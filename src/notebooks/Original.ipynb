{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import evaluate\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from transformers import Trainer\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TrainingArguments\n",
    "from transformers import AutoModelForTokenClassification\n",
    "from transformers import DataCollatorForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "finer = datasets.load_dataset(\"nlpaueb/finer-139\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entities Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "finer_train = finer['train']\n",
    "finer_test = finer['test']\n",
    "finer_validation = finer['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_names = finer_train.features[\"ner_tags\"].feature.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_entities = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution_entities(row):\n",
    "    for ner_tag in row['ner_tags']:\n",
    "        if ner_tag!=0:\n",
    "            if ner_tag in dict_entities:\n",
    "                dict_entities[ner_tag]+=1\n",
    "            else:\n",
    "                dict_entities[ner_tag]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f144ec447fb448ffad8728a851c5e9e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/900384 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "076d25e466b6457d9aad73500a4af362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/112494 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b639c5858d91409280ca6b99a4781e9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/108378 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "finer.map(distribution_entities)\n",
    "dict_sorted_finer_entities = dict(sorted(dict_entities.items(), key= lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{41: 18448,\n",
       " 87: 14730,\n",
       " 34: 14469,\n",
       " 37: 13158,\n",
       " 4: 10160,\n",
       " 8: 9162,\n",
       " 57: 8684,\n",
       " 6: 7458,\n",
       " 30: 6779,\n",
       " 140: 5763,\n",
       " 74: 5485,\n",
       " 64: 5473,\n",
       " 43: 5319,\n",
       " 128: 5277,\n",
       " 55: 4773,\n",
       " 83: 4543,\n",
       " 60: 4446,\n",
       " 107: 4328,\n",
       " 102: 4158,\n",
       " 129: 4006,\n",
       " 82: 3859,\n",
       " 35: 3833,\n",
       " 59: 3792,\n",
       " 32: 3770,\n",
       " 138: 3720,\n",
       " 17: 3688,\n",
       " 90: 3616,\n",
       " 70: 3597,\n",
       " 105: 3551,\n",
       " 131: 3540,\n",
       " 53: 3539,\n",
       " 158: 3406,\n",
       " 88: 3253,\n",
       " 113: 3178,\n",
       " 139: 3026,\n",
       " 40: 2954,\n",
       " 80: 2913,\n",
       " 132: 2774,\n",
       " 58: 2659,\n",
       " 133: 2598,\n",
       " 142: 2550,\n",
       " 145: 2528,\n",
       " 44: 2460,\n",
       " 152: 2450,\n",
       " 124: 2407,\n",
       " 67: 2400,\n",
       " 99: 2375,\n",
       " 156: 2372,\n",
       " 147: 2369,\n",
       " 16: 2339,\n",
       " 165: 2331,\n",
       " 85: 2281,\n",
       " 100: 2216,\n",
       " 25: 2195,\n",
       " 2: 2195,\n",
       " 91: 2114,\n",
       " 66: 2093,\n",
       " 14: 2062,\n",
       " 31: 2013,\n",
       " 50: 1942,\n",
       " 168: 1941,\n",
       " 51: 1895,\n",
       " 12: 1879,\n",
       " 72: 1873,\n",
       " 89: 1868,\n",
       " 52: 1866,\n",
       " 119: 1852,\n",
       " 94: 1779,\n",
       " 42: 1773,\n",
       " 77: 1768,\n",
       " 137: 1762,\n",
       " 18: 1757,\n",
       " 98: 1749,\n",
       " 159: 1728,\n",
       " 45: 1726,\n",
       " 144: 1725,\n",
       " 97: 1650,\n",
       " 92: 1647,\n",
       " 69: 1647,\n",
       " 62: 1631,\n",
       " 78: 1619,\n",
       " 149: 1582,\n",
       " 148: 1556,\n",
       " 39: 1540,\n",
       " 22: 1533,\n",
       " 73: 1530,\n",
       " 71: 1517,\n",
       " 93: 1508,\n",
       " 134: 1490,\n",
       " 26: 1489,\n",
       " 1: 1487,\n",
       " 150: 1441,\n",
       " 47: 1417,\n",
       " 48: 1414,\n",
       " 33: 1412,\n",
       " 76: 1398,\n",
       " 109: 1383,\n",
       " 27: 1363,\n",
       " 161: 1354,\n",
       " 163: 1340,\n",
       " 103: 1333,\n",
       " 54: 1320,\n",
       " 167: 1303,\n",
       " 169: 1301,\n",
       " 111: 1300,\n",
       " 36: 1295,\n",
       " 21: 1281,\n",
       " 84: 1279,\n",
       " 104: 1264,\n",
       " 108: 1264,\n",
       " 122: 1252,\n",
       " 56: 1239,\n",
       " 126: 1228,\n",
       " 151: 1223,\n",
       " 164: 1211,\n",
       " 23: 1200,\n",
       " 127: 1196,\n",
       " 10: 1193,\n",
       " 13: 1189,\n",
       " 95: 1167,\n",
       " 49: 1155,\n",
       " 63: 1148,\n",
       " 114: 1145,\n",
       " 24: 1142,\n",
       " 112: 1136,\n",
       " 5: 1118,\n",
       " 19: 1109,\n",
       " 143: 1104,\n",
       " 154: 1102,\n",
       " 121: 1085,\n",
       " 160: 1063,\n",
       " 115: 1060,\n",
       " 116: 1056,\n",
       " 29: 1050,\n",
       " 86: 1037,\n",
       " 130: 1031,\n",
       " 106: 1022,\n",
       " 75: 1017,\n",
       " 136: 1016,\n",
       " 20: 1005,\n",
       " 118: 984,\n",
       " 81: 882,\n",
       " 155: 672,\n",
       " 79: 657,\n",
       " 46: 653,\n",
       " 68: 643,\n",
       " 120: 435,\n",
       " 3: 420,\n",
       " 61: 285,\n",
       " 110: 130,\n",
       " 117: 30,\n",
       " 9: 22,\n",
       " 153: 17,\n",
       " 28: 12,\n",
       " 157: 10,\n",
       " 101: 9,\n",
       " 146: 8,\n",
       " 96: 8,\n",
       " 135: 7,\n",
       " 11: 3,\n",
       " 123: 3,\n",
       " 166: 2,\n",
       " 141: 2,\n",
       " 15: 2,\n",
       " 65: 2,\n",
       " 7: 2,\n",
       " 125: 2,\n",
       " 38: 1,\n",
       " 162: 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_sorted_finer_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (30, 10))\n",
    "plt.bar(dict_entities.keys(), dict_entities.values(), color ='green', width = 0.6)\n",
    "plt.xlabel(\"entities\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.title(\"Entities distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most repeated entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_mapping = {0:0, 41:1, 87:2, 34:3, 37:4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O means the word doesn’t correspond to any entity.\n",
    "# B-XXX means the word corresponds to the beginning of a XXX entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-DebtInstrumentInterestRateStatedPercentage': 1,\n",
       " 'B-LineOfCreditFacilityMaximumBorrowingCapacity': 2,\n",
       " 'B-DebtInstrumentBasisSpreadOnVariableRate1': 3,\n",
       " 'B-DebtInstrumentFaceAmount': 4}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity2index  = { entities_names[value]: dict_mapping[value] for value in [0, 41, 87, 34, 37]} \n",
    "entity2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2entity = { dict_mapping[value]: entities_names[value]  for value in [0, 41, 87, 34, 37]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-DebtInstrumentInterestRateStatedPercentage',\n",
       " 2: 'B-LineOfCreditFacilityMaximumBorrowingCapacity',\n",
       " 3: 'B-DebtInstrumentBasisSpreadOnVariableRate1',\n",
       " 4: 'B-DebtInstrumentFaceAmount'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2entity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new dataset with most repeated entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(row):\n",
    "    new_row_ner_tags = []\n",
    "    for tag in row['ner_tags']:\n",
    "        if tag in [0, 41, 87, 34, 37]:\n",
    "            new_row_ner_tags.append(dict_mapping[tag])\n",
    "        else:\n",
    "            new_row_ner_tags.append(0)\n",
    "    row['ner_tags'] = new_row_ner_tags\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_finer = finer.map(create_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 900384\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 112494\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 108378\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_finer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_finer_entities = new_finer.filter(lambda row: 1 in row['ner_tags'] or\n",
    "                                                  2 in row['ner_tags'] or\n",
    "                                                  3 in row['ner_tags'] or\n",
    "                                                  4 in row['ner_tags'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 28363\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 3741\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 3053\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_finer_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 28363\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 3741\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 3053\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_finer_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(new_finer_entities['train'][0]['ner_tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['As', 'of', 'November', '30', ',', '2015', ',', '$', '151.8', 'million', 'of', 'the', 'originated', 'loans', 'were', 'sold', 'into', 'a', 'securitization', 'trust', 'but', 'not', 'settled', 'and', 'thus', 'were', 'included', 'as', 'receivables', ',', 'net', '.', 'Notes', 'and', 'Other', 'Debts', 'Payable', 'In', 'November', '2013', ',', 'the', 'Rialto', 'segment', 'originally', 'issued', '$', '250', 'million', 'aggregate', 'principal', 'amount', 'of', 'the', '7.00', '%', 'senior', 'notes', 'due', '2018', '(', '\"', '7.00', '%', 'Senior', 'Notes', '\"', ')', ',', 'at', 'a', 'price', 'of', '100', '%', 'in', 'a', 'private', 'placement', '.']\n"
     ]
    }
   ],
   "source": [
    "print(new_finer_entities['train'][0]['tokens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add entities names to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_entities_names(row):\n",
    "  tag_name = {'ner_tags_name': [index2entity[idx] for idx in row['ner_tags']]}\n",
    "  return tag_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_finer_dataset = new_finer_entities.map(add_entities_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags', 'ner_tags_name'],\n",
       "        num_rows: 28363\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags', 'ner_tags_name'],\n",
       "        num_rows: 3741\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags', 'ner_tags_name'],\n",
       "        num_rows: 3053\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_finer_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(new_finer_dataset['train'][0]['ner_tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DebtInstrumentFaceAmount', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DebtInstrumentInterestRateStatedPercentage', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(new_finer_dataset['train'][0]['ner_tags_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model distilbert-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertTokenizerFast(name_or_path='distilbert-base-cased', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sample = new_finer_dataset['train'][0]['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['As', 'of', 'November', '30', ',', '2015', ',', '$', '151.8', 'million', 'of', 'the', 'originated', 'loans', 'were', 'sold', 'into', 'a', 'securitization', 'trust', 'but', 'not', 'settled', 'and', 'thus', 'were', 'included', 'as', 'receivables', ',', 'net', '.', 'Notes', 'and', 'Other', 'Debts', 'Payable', 'In', 'November', '2013', ',', 'the', 'Rialto', 'segment', 'originally', 'issued', '$', '250', 'million', 'aggregate', 'principal', 'amount', 'of', 'the', '7.00', '%', 'senior', 'notes', 'due', '2018', '(', '\"', '7.00', '%', 'Senior', 'Notes', '\"', ')', ',', 'at', 'a', 'price', 'of', '100', '%', 'in', 'a', 'private', 'placement', '.']\n"
     ]
    }
   ],
   "source": [
    "print(first_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'As', 'of', 'November', '30', ',', '2015', ',', '$', '151', '.', '8', 'million', 'of', 'the', 'originated', 'loans', 'were', 'sold', 'into', 'a', 'se', '##cu', '##rit', '##ization', 'trust', 'but', 'not', 'settled', 'and', 'thus', 'were', 'included', 'as', 're', '##ce', '##ivable', '##s', ',', 'net', '.', 'Notes', 'and', 'Other', 'De', '##bt', '##s', 'Pay', '##able', 'In', 'November', '2013', ',', 'the', 'R', '##ial', '##to', 'segment', 'originally', 'issued', '$', '250', 'million', 'aggregate', 'principal', 'amount', 'of', 'the', '7', '.', '00', '%', 'senior', 'notes', 'due', '2018', '(', '\"', '7', '.', '00', '%', 'Senior', 'Notes', '\"', ')', ',', 'at', 'a', 'price', 'of', '100', '%', 'in', 'a', 'private', 'placement', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "first_sample_tokens = tokenizer(first_sample, is_split_into_words=True)\n",
    "print(first_sample_tokens.tokens())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 0, 1, 2, 3, 4, 5, 6, 7, 8, 8, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 18, 18, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 28, 28, 28, 29, 30, 31, 32, 33, 34, 35, 35, 35, 36, 36, 37, 38, 39, 40, 41, 42, 42, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 54, 54, 55, 56, 57, 58, 59, 60, 61, 62, 62, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, None]\n"
     ]
    }
   ],
   "source": [
    "print(first_sample_tokens.word_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_sample_tokens.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(first_sample_tokens['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_ner_tags(ner_tags, word_ids, fill_complete_word=True):\n",
    "  new_ner_tags = []\n",
    "  previous_word_id = None\n",
    "  for word_id in word_ids:\n",
    "    if word_id is None:\n",
    "      # Special tokens ([CLS], [SEP]) have a word_id that is None, \n",
    "      # they are set to -100 to be ignored in the loss function.\n",
    "      new_ner_tags.append(-100)\n",
    "    elif word_id != previous_word_id:\n",
    "      new_ner_tags.append(ner_tags[word_id])\n",
    "    else:\n",
    "      # if fill_complete_word=True, pad with ner_tags[word_id] value the complete word\n",
    "      new_ner_tags.append(ner_tags[word_id] if fill_complete_word else -100)\n",
    "    previous_word_id = word_id\n",
    "  return new_ner_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sample_ner_tags = new_finer_dataset['train'][0]['ner_tags']\n",
    "first_sample_word_ids = first_sample_tokens.word_ids()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(first_sample_ner_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 0, 1, 2, 3, 4, 5, 6, 7, 8, 8, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 18, 18, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 28, 28, 28, 29, 30, 31, 32, 33, 34, 35, 35, 35, 36, 36, 37, 38, 39, 40, 41, 42, 42, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 54, 54, 55, 56, 57, 58, 59, 60, 61, 62, 62, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, None]\n"
     ]
    }
   ],
   "source": [
    "print(first_sample_word_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sample_padded_ner_tags = padding_ner_tags(first_sample_ner_tags, first_sample_word_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_tokenize_padding(rows):\n",
    "  rows_tokenized = tokenizer(rows['tokens'], truncation=True, is_split_into_words=True)\n",
    "  rows_ner_tags = rows['ner_tags']\n",
    "  new_labels = []\n",
    "  for i, ner_tags in enumerate(rows_ner_tags):\n",
    "    word_ids = rows_tokenized.word_ids(i)\n",
    "    new_labels.append(padding_ner_tags(ner_tags, word_ids, fill_complete_word=True))\n",
    "  rows_tokenized['labels'] = new_labels\n",
    "  return rows_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding ner_tags and tokenize, additionally remove 'id', 'tokens', 'ner_tags', 'ner_tags_name' \n",
    "tokenized_datasets = new_finer_dataset.map(batch_tokenize_padding, batched=True, remove_columns=new_finer_dataset['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 28363\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3741\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3053\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data collator that will dynamically pad the inputs received, as well as the labels. \n",
    "# The id to use when padding the labels (-100 will be automatically ignore by PyTorch loss functions)\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorForTokenClassification(tokenizer=DistilBertTokenizerFast(name_or_path='distilbert-base-cased', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}, padding=True, max_length=None, pad_to_multiple_of=None, label_pad_token_id=-100, return_tensors='pt')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1249,  1104,  1379,  1476,   117,  1410,   117,   109, 17576,\n",
       "           119,   129,  1550,  1104,  1103,  7506, 11453,  1127,  1962,  1154,\n",
       "           170, 14516, 10182,  7729,  2734,  3496,  1133,  1136,  3035,  1105,\n",
       "          2456,  1127,  1529,  1112,  1231,  2093, 25768,  1116,   117,  5795,\n",
       "           119,  8797,  1105,  2189,  3177, 21238,  1116, 22531,  1895,  1130,\n",
       "          1379,  1381,   117,  1103,   155,  2916,  2430,  6441,  2034,  3010,\n",
       "           109,  4805,  1550,  9453,  3981,  2971,  1104,  1103,   128,   119,\n",
       "          3135,   110,  2682,  3697,  1496,  1857,   113,   107,   128,   119,\n",
       "          3135,   110,  4308,  8797,   107,   114,   117,  1120,   170,  3945,\n",
       "          1104,  1620,   110,  1107,   170,  2029, 12693,   119,   102],\n",
       "        [  101,  1130,  1345,  1387,   117,  1103,   155,  2916,  2430,  6441,\n",
       "          3010,  1126,  2509,   109,  1620,  1550,  1104,  1103,   128,   119,\n",
       "          3135,   110,  4308,  8797,   117,  1120,   170,  3945,  1104,  9081,\n",
       "           119,  1512,   110,  1104,  1147,  1339,  2860,  1107,   170,  2029,\n",
       "         12693,   119,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0]]), 'labels': tensor([[-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    4,    0,    0,    0,    0,    0,    0,    1,    1,    1,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0, -100],\n",
       "        [-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    4,    0,    0,    0,    1,    1,    1,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100]])}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynamic_padding_example = data_collator([tokenized_datasets['train'][i] for i in range(0,2)])\n",
    "dynamic_padding_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "print(dynamic_padding_example.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load('seqeval')\n",
    "#metric = datasets.load_metric(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sample_ner_tags = new_finer_dataset['train'][0]['ner_tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(first_sample_ner_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DebtInstrumentFaceAmount', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DebtInstrumentInterestRateStatedPercentage', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "ner_tags_names_first_sample = [index2entity[ner_tag] for ner_tag in first_sample_ner_tags]\n",
    "print(ner_tags_names_first_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_first_sample = ner_tags_names_first_sample.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_first_sample[0] = 'B-DebtInstrumentFaceAmount'\n",
    "predictions_first_sample[1] = 'B-DebtInstrumentInterestRateStatedPercentage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-DebtInstrumentFaceAmount', 'B-DebtInstrumentInterestRateStatedPercentage', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DebtInstrumentFaceAmount', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DebtInstrumentInterestRateStatedPercentage', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(predictions_first_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DebtInstrumentFaceAmount': {'precision': 0.5,\n",
       "  'recall': 1.0,\n",
       "  'f1': 0.6666666666666666,\n",
       "  'number': 1},\n",
       " 'DebtInstrumentInterestRateStatedPercentage': {'precision': 0.5,\n",
       "  'recall': 1.0,\n",
       "  'f1': 0.6666666666666666,\n",
       "  'number': 1},\n",
       " 'overall_precision': 0.5,\n",
       " 'overall_recall': 1.0,\n",
       " 'overall_f1': 0.6666666666666666,\n",
       " 'overall_accuracy': 0.975}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.compute(predictions=[predictions_first_sample], references=[ner_tags_names_first_sample])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-DebtInstrumentInterestRateStatedPercentage',\n",
       " 2: 'B-LineOfCreditFacilityMaximumBorrowingCapacity',\n",
       " 3: 'B-DebtInstrumentBasisSpreadOnVariableRate1',\n",
       " 4: 'B-DebtInstrumentFaceAmount'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-DebtInstrumentInterestRateStatedPercentage': 1,\n",
       " 'B-LineOfCreditFacilityMaximumBorrowingCapacity': 2,\n",
       " 'B-DebtInstrumentBasisSpreadOnVariableRate1': 3,\n",
       " 'B-DebtInstrumentFaceAmount': 4}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained( \"distilbert-base-cased\", id2label=index2entity, label2id=entity2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForTokenClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetunned_ner_classifier_distil_bert = 'ner-classifier-distil-bert'\n",
    "args = TrainingArguments(finetunned_ner_classifier_distil_bert,\n",
    "                         evaluation_strategy = \"epoch\",\n",
    "                         save_strategy=\"epoch\",\n",
    "                         learning_rate = 2e-5,\n",
    "                         num_train_epochs=5,\n",
    "                         weight_decay=0.01,\n",
    "                         logging_steps=50 # default 500\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 28363\n",
       "})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 2500\n",
       "})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = tokenized_datasets['train'].select(range(2500))\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 3741\n",
       "})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 500\n",
       "})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset = tokenized_datasets['validation'].select(range(500))\n",
    "eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "  logits, labels = eval_preds\n",
    "  #print(f'labels.shape: {labels.shape}')\n",
    "  #print(f'logits.shape: {logits.shape}')\n",
    "  #print(f'logits: {logits}')\n",
    "  #print(f'labels: {labels}')\n",
    "  predictions = np.argmax(logits, axis=2)\n",
    "  #print(f'predictions: {predictions}')\n",
    "  #print(f'predictions.shape: {predictions.shape}')\n",
    "  true_labels = [[index2entity[l] for l in label if l!=-100] for label in labels]\n",
    "  #print(f'true_labels: {true_labels}')\n",
    "  #print(f'true_labels.len: {len(true_labels[0])}')\n",
    "  true_predictions = [[index2entity[p] for p,l in zip(prediction, label) if l!=-100] for prediction, label in zip(predictions, labels)]\n",
    "  #print(f'true_predictions: {true_predictions}')\n",
    "  #print(f'true_predictions.len: {len(true_predictions[0])}')\n",
    "  all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "  print(f'all_metrics: {all_metrics}')\n",
    "  return {\"precision\": all_metrics['overall_precision'],\n",
    "          \"recall\": all_metrics['overall_recall'],\n",
    "          \"f1\": all_metrics['overall_f1'],\n",
    "          \"accuracy\": all_metrics['overall_accuracy']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model,\n",
    "                  args=args,\n",
    "                  train_dataset=train_dataset,\n",
    "                  eval_dataset=eval_dataset,\n",
    "                  data_collator=data_collator,\n",
    "                  compute_metrics=compute_metrics,\n",
    "                  tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ea9adc42214806b49a0b299d49041b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1565 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3884, 'grad_norm': 0.5011580586433411, 'learning_rate': 1.9361022364217256e-05, 'epoch': 0.16}\n",
      "{'loss': 0.0914, 'grad_norm': 0.5986570715904236, 'learning_rate': 1.8722044728434506e-05, 'epoch': 0.32}\n",
      "{'loss': 0.0743, 'grad_norm': 0.9875678420066833, 'learning_rate': 1.808306709265176e-05, 'epoch': 0.48}\n",
      "{'loss': 0.0535, 'grad_norm': 0.7359943985939026, 'learning_rate': 1.744408945686901e-05, 'epoch': 0.64}\n",
      "{'loss': 0.0484, 'grad_norm': 0.938058614730835, 'learning_rate': 1.6805111821086264e-05, 'epoch': 0.8}\n",
      "{'loss': 0.0429, 'grad_norm': 1.3367325067520142, 'learning_rate': 1.6166134185303515e-05, 'epoch': 0.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "304f821d275144fdb752a9ec9f3da551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_metrics: {'DebtInstrumentBasisSpreadOnVariableRate1': {'precision': 0.7440677966101695, 'recall': 0.9606126914660832, 'f1': 0.8385864374403057, 'number': 457}, 'DebtInstrumentFaceAmount': {'precision': 0.7807692307692308, 'recall': 0.4356223175965665, 'f1': 0.559228650137741, 'number': 466}, 'DebtInstrumentInterestRateStatedPercentage': {'precision': 0.9021852237252862, 'recall': 0.9517014270032931, 'f1': 0.9262820512820514, 'number': 911}, 'LineOfCreditFacilityMaximumBorrowingCapacity': {'precision': 0.6866952789699571, 'recall': 0.9073724007561437, 'f1': 0.7817589576547231, 'number': 529}, 'overall_precision': 0.7924302788844622, 'overall_recall': 0.841726618705036, 'overall_f1': 0.8163349066283603, 'overall_accuracy': 0.9791696148076868}\n",
      "{'eval_loss': 0.062302179634571075, 'eval_precision': 0.7924302788844622, 'eval_recall': 0.841726618705036, 'eval_f1': 0.8163349066283603, 'eval_accuracy': 0.9791696148076868, 'eval_runtime': 8.7869, 'eval_samples_per_second': 56.903, 'eval_steps_per_second': 7.17, 'epoch': 1.0}\n",
      "{'loss': 0.0305, 'grad_norm': 0.5679680705070496, 'learning_rate': 1.552715654952077e-05, 'epoch': 1.12}\n",
      "{'loss': 0.0353, 'grad_norm': 1.088419795036316, 'learning_rate': 1.488817891373802e-05, 'epoch': 1.28}\n",
      "{'loss': 0.0307, 'grad_norm': 0.8558123707771301, 'learning_rate': 1.4249201277955273e-05, 'epoch': 1.44}\n",
      "{'loss': 0.023, 'grad_norm': 0.5220783948898315, 'learning_rate': 1.3610223642172523e-05, 'epoch': 1.6}\n",
      "{'loss': 0.0234, 'grad_norm': 0.3949487805366516, 'learning_rate': 1.2971246006389777e-05, 'epoch': 1.76}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 5.20 GB, other allocations: 12.86 GB, max allowed: 18.13 GB). Tried to allocate 84.95 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/virtualenvs/NER-classifier-DistilBERT/lib/python3.10/site-packages/transformers/trainer.py:1624\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1622\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1629\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/virtualenvs/NER-classifier-DistilBERT/lib/python3.10/site-packages/transformers/trainer.py:2017\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2014\u001b[0m         grad_norm \u001b[38;5;241m=\u001b[39m _grad_norm\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m _grad_norm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2016\u001b[0m \u001b[38;5;66;03m# Optimizer step\u001b[39;00m\n\u001b[0;32m-> 2017\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2018\u001b[0m optimizer_was_run \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39moptimizer_step_was_skipped\n\u001b[1;32m   2019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimizer_was_run:\n\u001b[1;32m   2020\u001b[0m     \u001b[38;5;66;03m# Delay optimizer scheduling until metrics are generated\u001b[39;00m\n",
      "File \u001b[0;32m~/virtualenvs/NER-classifier-DistilBERT/lib/python3.10/site-packages/accelerate/optimizer.py:145\u001b[0m, in \u001b[0;36mAcceleratedOptimizer.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerate_step_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/virtualenvs/NER-classifier-DistilBERT/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:75\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     74\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/virtualenvs/NER-classifier-DistilBERT/lib/python3.10/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/virtualenvs/NER-classifier-DistilBERT/lib/python3.10/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/virtualenvs/NER-classifier-DistilBERT/lib/python3.10/site-packages/torch/optim/adamw.py:187\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    174\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    176\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    177\u001b[0m         group,\n\u001b[1;32m    178\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    184\u001b[0m         state_steps,\n\u001b[1;32m    185\u001b[0m     )\n\u001b[0;32m--> 187\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/virtualenvs/NER-classifier-DistilBERT/lib/python3.10/site-packages/torch/optim/adamw.py:339\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    337\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 339\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/virtualenvs/NER-classifier-DistilBERT/lib/python3.10/site-packages/torch/optim/adamw.py:470\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[1;32m    468\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 470\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    472\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 5.20 GB, other allocations: 12.86 GB, max allowed: 18.13 GB). Tried to allocate 84.95 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(finetunned_ner_classifier_distil_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.push_to_hub(commit_message=\"Training first version\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = ' '.join( new_finer_dataset['test'][0]['tokens'])\n",
    "test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample[93:95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_classifier = pipeline(\n",
    "    \"token-classification\", model=finetunned_ner_classifier_distil_bert, aggregation_strategy=\"simple\"\n",
    ")\n",
    "ner_classifier(test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_tokenizer = AutoTokenizer.from_pretrained(finetunned_ner_classifier_distil_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = AutoModelForTokenClassification.from_pretrained(finetunned_ner_classifier_distil_bert, num_labels=len(index2entity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_test_sample = saved_tokenizer(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_logits = saved_model.forward(input_ids=torch.tensor(tokens_test_sample['input_ids']).unsqueeze(0), attention_mask=torch.tensor(tokens_test_sample['attention_mask']).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.argmax(preds_logits.logits.squeeze(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = saved_tokenizer.batch_decode(tokens_test_sample['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_preds = [index2entity[int(i)] for i in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(value_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sample(row):\n",
    "    text = row['tokens']\n",
    "    print(f'len(text): {len(text):}')\n",
    "    tokens_sample = saved_tokenizer(text, is_split_into_words=True)\n",
    "    print(f'tokens_sample: {tokens_sample}')\n",
    "    prediction_logits_sample = saved_model.forward(input_ids=torch.tensor(tokens_sample['input_ids']).unsqueeze(0), \n",
    "                                attention_mask=torch.tensor(tokens_sample['attention_mask']).unsqueeze(0))\n",
    "    print(f'prediction_logits_sample: {prediction_logits_sample}')\n",
    "    prediction_sample = torch.argmax(prediction_logits_sample.logits.squeeze(), axis=1)\n",
    "    value_preds = [index2entity[int(i)] for i in prediction_sample]\n",
    "    return value_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict_sample(new_finer_dataset['test'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_finer_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tokenized_sample(rows):\n",
    "    #print(f\"rows[input_ids]: {rows['input_ids']}\")\n",
    "    #print(f\"rows[attention_mask]: {rows['attention_mask']}\")\n",
    "    logits = saved_model.forward(input_ids=torch.tensor(rows['input_ids']).unsqueeze(0), \n",
    "                                attention_mask=torch.tensor(rows['attention_mask']).unsqueeze(0))    \n",
    "    #print(f'logits: {logits}')\n",
    "    value_preds = torch.argmax(logits.logits.squeeze(), axis=1)\n",
    "    #print(f'value_preds: {value_preds}')\n",
    "    #entity_pred = [index2entity[int(i)] for i in value_preds]\n",
    "    #print(f'entity_preds: {entity_pred}')\n",
    "    rows['value_preds'] = value_preds\n",
    "    return rows\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tokenized_datasets['test'].select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_test_dataset = test_dataset.map(predict_tokenized_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_preds = predicted_test_dataset['value_preds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = predicted_test_dataset['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "  value_preds, labels = eval_preds\n",
    "  #print(f'value_preds: {value_preds}')\n",
    "  #print(f'labels: {labels}')\n",
    "  true_labels = [[index2entity[l] for l in label if l!=-100] for label in labels]\n",
    "  #print(f'true_labels: {true_labels}')\n",
    "  #print(f'true_labels.len: {len(true_labels[0])}')\n",
    "  true_predictions = [[index2entity[p] for p,l in zip(value_preds, label) if l!=-100] for value_preds, label in zip(value_preds, labels)]\n",
    "  #print(f'true_predictions: {true_predictions}')\n",
    "  #print(f'true_predictions.len: {len(true_predictions[0])}')\n",
    "  all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "  print(f'all_metrics: {all_metrics}')\n",
    "  return {\"precision\": all_metrics['overall_precision'],\n",
    "          \"recall\": all_metrics['overall_recall'],\n",
    "          \"f1\": all_metrics['overall_f1'],\n",
    "          \"accuracy\": all_metrics['overall_accuracy']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'value_preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m compute_metrics((\u001b[43mvalue_preds\u001b[49m, labels))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'value_preds' is not defined"
     ]
    }
   ],
   "source": [
    "compute_metrics((value_preds, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to OONX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimum.onnxruntime import ORTModelForSequenceClassification\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"distilbert_base_uncased_squad\"\n",
    "save_directory = \"onnx/\"\n",
    "\n",
    "# Load a model from transformers and export it to ONNX\n",
    "ort_model = ORTModelForSequenceClassification.from_pretrained(model_checkpoint, export=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "# Save the onnx model and tokenizer\n",
    "ort_model.save_pretrained(save_directory)\n",
    "tokenizer.save_pretrained(save_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
